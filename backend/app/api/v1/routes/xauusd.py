"""XAU/USD routes"""
from fastapi import APIRouter, Depends
from typing import Optional
from datetime import datetime
from functools import lru_cache

from ....core.dependencies import (
    get_market_data_service,
    get_prediction_service,
    get_prediction_repo
)

router = APIRouter()


@router.get("/")
@router.get("")
async def get_daily_data(
    days: int = 90,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    market_data_service=Depends(get_market_data_service),
    prediction_service=Depends(get_prediction_service)
):
    """Get XAU/USD daily data with model information
    
    Args:
        days: Number of days to fetch (default: 90)
        start_date: Optional start date in YYYY-MM-DD format
        end_date: Optional end date in YYYY-MM-DD format
        
    Note: If start_date/end_date are provided, they take precedence over days parameter
    """
    from ....core.response_cache import response_cache
    
    # Create cache key from parameters
    cache_key_parts = [f"daily_data", f"days:{days}"]
    if start_date:
        cache_key_parts.append(f"start:{start_date}")
    if end_date:
        cache_key_parts.append(f"end:{end_date}")
    cache_key = "_".join(cache_key_parts)
    
    # Cache for 30 seconds (market data changes frequently)
    cached = response_cache.get(cache_key, ttl=30)
    if cached is not None:
        return cached
    
    data = market_data_service.get_daily_data(days=days, start_date=start_date, end_date=end_date)
    
    # Add model info if not already present (reuse cached model info response)
    if isinstance(data, dict) and "model_info" not in data:
        # Try to get from cached model-info endpoint response
        model_info_cache_key = "model_info"
        cached_model_info_response = response_cache.get(model_info_cache_key, ttl=30)
        if cached_model_info_response and isinstance(cached_model_info_response, dict):
            data["model_info"] = cached_model_info_response.get("model", {})
        else:
            # Fallback: get directly (will be slow but cached for next time)
            data["model_info"] = prediction_service.get_model_info()
    
    # Cache the result
    response_cache.set(cache_key, data, ttl=30)
    return data


@router.get("/realtime")
async def get_realtime_price(
    market_data_service=Depends(get_market_data_service)
):
    """Get real-time XAU/USD price"""
    return market_data_service.get_realtime_price()


@router.get("/enhanced-prediction")
async def get_enhanced_prediction(
    market_data_service=Depends(get_market_data_service),
    prediction_service=Depends(get_prediction_service),
    prediction_repo=Depends(get_prediction_repo)
):
    """Get enhanced prediction with news sentiment analysis"""
    from ....core.logging_config import get_logger
    logger = get_logger(__name__)
    
    try:
        # Check if prediction service is available
        if prediction_service is None:
            logger.error("Prediction service is not available")
            return {
                "status": "error",
                "message": "Prediction service is not initialized. Please check backend logs.",
                "timestamp": datetime.now().isoformat()
            }

        # Get current price
        try:
            current_price_data = market_data_service.get_realtime_price()
            current_price = current_price_data.get('current_price', 0.0)
            status = current_price_data.get('status', 'success')
            
            if current_price <= 0:
                # If rate limited, provide more informative message
                if status == 'rate_limited':
                    rate_limit_info = current_price_data.get('rate_limit_info', {})
                    wait_seconds = rate_limit_info.get('wait_seconds', 0)
                    logger.warning(f"Invalid current price: {current_price} (rate limited, retry after {wait_seconds}s)")
                    return {
                        "status": "rate_limited",
                        "message": f"Data provider rate limit. Please retry after {wait_seconds} seconds.",
                        "timestamp": datetime.now().isoformat(),
                        "rate_limit_info": rate_limit_info
                    }
                logger.warning(f"Invalid current price: {current_price}")
                return {
                    "status": "error",
                    "message": "Unable to fetch current market price. Please try again later.",
                    "timestamp": datetime.now().isoformat()
                }
        except Exception as e:
            logger.error(f"Error fetching current price: {e}", exc_info=True)
            return {
                "status": "error",
                "message": f"Error fetching current market price: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

        # Get stored prediction from database (generated by background task)
        # If no stored prediction exists, generate one on-demand as fallback
        try:
            from ....services.market_data_service import get_next_trading_day
            next_trading_day_dt = get_next_trading_day()
            next_day = next_trading_day_dt.strftime("%Y-%m-%d")
            
            if prediction_repo.prediction_exists_for_date(next_day):
                predicted_price = prediction_repo.get_prediction_for_date(next_day)
                stored_prediction = prediction_repo.get_prediction_details_for_date(next_day)
                if stored_prediction and stored_prediction.get('method'):
                    prediction_method = stored_prediction.get('method')
                else:
                    prediction_method = prediction_service.get_model_display_name()
                logger.debug(f"Using stored prediction for {next_day}: ${predicted_price:.2f} (Method: {prediction_method})")
            else:
                # No stored prediction found - generate on-demand as fallback
                logger.info(f"No stored prediction found for {next_day}. Generating prediction on-demand...")
                
                # Check which models are available
                has_enhanced = prediction_service.news_enhanced_predictor is not None and prediction_service.news_enhanced_predictor.model is not None
                has_lasso = prediction_service.lasso_predictor is not None and prediction_service.lasso_predictor.model is not None
                
                if not has_enhanced and not has_lasso:
                    logger.error(f"No stored prediction found for {next_day} and no ML models are available.")
                    return {
                        "status": "error",
                        "message": "No stored prediction found and no ML models are available. Please ensure model files are present and check backend logs for initialization errors.",
                        "timestamp": datetime.now().isoformat()
                    }
                
                # Generate prediction on-demand
                try:
                    predicted_price = prediction_service.predict_next_day()
                    
                    if predicted_price is None:
                        logger.error(f"Failed to generate prediction for {next_day} - service returned None")
                        return {
                            "status": "error",
                            "message": f"Failed to generate prediction for {next_day}. Both models are available but prediction failed. Please check backend logs for details.",
                            "timestamp": datetime.now().isoformat()
                        }
                    
                    # Save the generated prediction for future use
                    prediction_method = prediction_service.get_model_display_name()
                    prediction_repo.save_prediction(next_day, predicted_price, prediction_method=prediction_method)
                    logger.info(f"‚úÖ Generated and saved prediction for {next_day}: ${predicted_price:.2f} (Method: {prediction_method})")
                except Exception as gen_error:
                    logger.error(f"Error generating prediction on-demand: {gen_error}", exc_info=True)
                    return {
                        "status": "error",
                        "message": f"Error generating prediction: {str(gen_error)}",
                        "timestamp": datetime.now().isoformat()
                    }
        except Exception as e:
            logger.error(f"Error retrieving or generating prediction: {e}", exc_info=True)
            return {
                "status": "error",
                "message": f"Error retrieving prediction: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

        # Validate prediction is within reasonable range (gold typically $1,000-$5,000 per troy ounce)
        # If prediction is outside this range, it's likely a model error
        MIN_REASONABLE_PRICE = 1000.0
        MAX_REASONABLE_PRICE = 5000.0
        MAX_PERCENT_CHANGE = 50.0  # Max 50% change in one day is extremely rare
        
        if predicted_price < MIN_REASONABLE_PRICE or predicted_price > MAX_REASONABLE_PRICE:
            logger.error(
                f"‚ö†Ô∏è  Prediction {predicted_price:.2f} is outside reasonable range "
                f"(${MIN_REASONABLE_PRICE:.2f} - ${MAX_REASONABLE_PRICE:.2f}). "
                f"Current price: ${current_price:.2f}. This may indicate a model error."
            )
            # Try fallback model if available
            if prediction_service.lasso_predictor and prediction_service.lasso_predictor.model is not None:
                logger.info("üîÑ Attempting fallback model due to unreasonable prediction...")
                try:
                    fallback_prediction = prediction_service.lasso_predictor.predict_next_price(
                        prediction_service.lasso_predictor.create_fundamental_features(
                            prediction_service.lasso_predictor.fetch_market_data()
                        )
                    )
                    if fallback_prediction and MIN_REASONABLE_PRICE <= fallback_prediction <= MAX_REASONABLE_PRICE:
                        logger.info(f"‚úÖ Fallback model produced reasonable prediction: ${fallback_prediction:.2f}")
                        predicted_price = fallback_prediction
                    else:
                        logger.warning(f"‚ö†Ô∏è  Fallback model also produced unreasonable prediction: ${fallback_prediction:.2f}")
                except Exception as fallback_error:
                    logger.error(f"Fallback model failed: {fallback_error}")

        # Calculate change
        change = predicted_price - current_price
        change_percentage = (change / current_price *
                             100) if current_price > 0 else 0
        
        # Warn if change percentage is extreme
        if abs(change_percentage) > MAX_PERCENT_CHANGE:
            logger.warning(
                f"‚ö†Ô∏è  Extreme predicted change: {change_percentage:.2f}% "
                f"(${change:.2f}). This may indicate a model error."
            )

        # Get method name and model information
        try:
            # Use stored method if available, otherwise get from service
            method = prediction_method if 'prediction_method' in locals() and prediction_method else prediction_service.get_model_display_name()
            model_info = prediction_service.get_model_info()
        except Exception as e:
            logger.error(f"Error getting model info: {e}", exc_info=True)
            method = prediction_method if 'prediction_method' in locals() and prediction_method else "Unknown"
            model_info = {}

        return {
            "status": "success",
            "prediction": {
                "next_day_price": round(predicted_price, 2),
                "current_price": round(current_price, 2),
                "change": round(change, 2),
                "change_percentage": round(change_percentage, 2),
                "method": method
            },
            "model": {
                "name": model_info.get("active_model", "Unknown"),
                "type": model_info.get("model_type", "Unknown"),
                "r2_score": model_info.get("r2_score"),  # Primary (live if available)
                "training_r2_score": model_info.get("training_r2_score"),  # Static from training
                "live_r2_score": model_info.get("live_r2_score"),  # Dynamic from predictions
                "features": {
                    "total": model_info.get("features_count"),
                    "selected": model_info.get("selected_features_count"),
                    "top_features": model_info.get("selected_features", [])[:5]  # Top 5 features
                },
                "fallback_available": model_info.get("fallback_available", False),
                "live_accuracy_stats": model_info.get("live_accuracy_stats")  # Full live stats
            },
            "sentiment": {
                "combined_sentiment": 0.0,  # Placeholder - would need news analyzer
                "news_volume": 0,
                "sentiment_trend": 0.0
            },
            "top_features": [],  # Placeholder
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Unexpected error getting enhanced prediction: {e}", exc_info=True)
        return {
            "status": "error",
            "message": f"Unexpected error: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }


@router.get("/accuracy-visualization")
async def get_accuracy_visualization(
    days: int = 90,
    prediction_repo=Depends(get_prediction_repo)
):
    """Get accuracy statistics for visualization"""
    from ....core.logging_config import get_logger
    from ....core.response_cache import response_cache
    logger = get_logger(__name__)
    
    # Cache based on days parameter (60 seconds TTL)
    cache_key = f"accuracy_visualization_{days}"
    cached = response_cache.get(cache_key, ttl=60)
    if cached is not None:
        return cached
    
    try:
        # Check if prediction repo is available
        if prediction_repo is None:
            logger.error("Prediction repository is not available")
            return {
                "status": "error",
                "message": "Prediction repository is not initialized. Please check backend logs.",
                "timestamp": datetime.now().isoformat()
            }

        # Validate days parameter
        if days < 1 or days > 365:
            days = 90  # Default to 90 days if invalid
            logger.warning(f"Invalid days parameter, using default: 90")

        # Get visualization data
        try:
            visualization_data = prediction_repo.get_accuracy_visualization_data(days=days)
        except Exception as e:
            logger.error(f"Error getting accuracy visualization data: {e}", exc_info=True)
            return {
                "status": "error",
                "message": f"Error retrieving accuracy data: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }

        # Check if data is empty
        if not visualization_data or not visualization_data.get('data'):
            logger.info(f"No accuracy data available for the last {days} days")
            return {
                "status": "success",
                "data": [],
                "statistics": {
                    "average_accuracy": 0.0,
                    "min_accuracy": 0.0,
                    "max_accuracy": 0.0,
                    "average_error": 0.0,
                    "total_predictions": 0
                },
                "message": f"No accuracy data available yet. The chart will appear once predictions are evaluated with actual prices.",
                "timestamp": datetime.now().isoformat()
            }

        result = {
            "status": "success",
            "data": visualization_data['data'],
            "statistics": visualization_data['statistics'],
            "timestamp": datetime.now().isoformat()
        }
        # Cache the result
        response_cache.set(cache_key, result, ttl=60)
        return result
    except Exception as e:
        logger.error(f"Unexpected error getting accuracy visualization: {e}", exc_info=True)
        return {
            "status": "error",
            "message": f"Unexpected error: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }


@router.get("/model-info")
async def get_model_info(
    prediction_service=Depends(get_prediction_service)
):
    """Get detailed information about the active ML model with live accuracy metrics
    
    Returns:
        - training_r2_score: Static R¬≤ from when model was trained (doesn't change)
        - live_r2_score: Dynamic R¬≤ calculated from actual predictions vs real prices (updates with each prediction)
        - r2_score: Primary score (live if available, otherwise training)
        - live_accuracy_stats: Full live accuracy statistics including average_accuracy, total_predictions, etc.
    """
    from ....core.logging_config import get_logger
    from ....core.response_cache import response_cache
    logger = get_logger(__name__)
    
    # Cache model info for 30 seconds (model info doesn't change frequently)
    cache_key = "model_info"
    cached = response_cache.get(cache_key, ttl=30)
    if cached is not None:
        return cached
    
    try:
        model_info = prediction_service.get_model_info()
        
        # Ensure model_info is a valid dict
        if not isinstance(model_info, dict):
            logger.warning(f"get_model_info() returned non-dict: {type(model_info)}")
            model_info = {
                "active_model": None,
                "model_type": None,
                "training_r2_score": None,
                "live_r2_score": None,
                "r2_score": None,
                "features_count": None,
                "selected_features_count": None,
                "fallback_available": False,
                "live_accuracy_stats": None
            }
        
        # Add explanation for the R¬≤ scores
        r2_explanation = {
            "training_r2_score": "Static accuracy from model training (historical test data)",
            "live_r2_score": "Dynamic accuracy from real predictions vs actual market prices (updates automatically)",
            "r2_score": "Primary score shown to users (uses live if available)"
        }
        
        result = {
            "status": "success",
            "model": model_info,
            "r2_explanation": r2_explanation,
            "timestamp": datetime.now().isoformat()
        }
        # Cache the result
        response_cache.set(cache_key, result, ttl=30)
        return result
    except Exception as e:
        logger.error(f"Error getting model info: {e}", exc_info=True)
        # Return a valid response even on error
        return {
            "status": "error",
            "message": str(e),
            "model": {
                "active_model": None,
                "model_type": None,
                "training_r2_score": None,
                "live_r2_score": None,
                "r2_score": None,
                "features_count": None,
                "selected_features_count": None,
                "fallback_available": False,
                "live_accuracy_stats": None
            },
            "timestamp": datetime.now().isoformat()
        }


@router.get("/prediction-stats")
async def get_prediction_stats(
    prediction_repo=Depends(get_prediction_repo)
):
    """Get comprehensive prediction statistics (all time)"""
    from ....core.response_cache import response_cache
    
    # Cache stats for 60 seconds
    cache_key = "prediction_stats"
    cached = response_cache.get(cache_key, ttl=60)
    if cached is not None:
        return cached
    
    try:
        stats = prediction_repo.get_comprehensive_stats()
        result = {
            "status": "success",
            "data": {
                "total_predictions": stats['total_predictions'],
                "evaluated": {
                    "count": stats['evaluated_predictions'],
                    "with_results": stats['evaluated_predictions'],
                    "average_accuracy": stats['average_accuracy']
                },
                "pending": {
                    "count": stats['pending_predictions'],
                    "awaiting_market_results": stats['pending_predictions']
                },
                "r2_score": stats.get('r2_score'),
                "evaluation_rate_percent": stats['evaluation_rate']
            }
        }
        # Cache the result
        response_cache.set(cache_key, result, ttl=60)
        return result
    except Exception as e:
        from ....core.logging_config import get_logger
        logger = get_logger(__name__)
        logger.error(f"Error getting prediction stats: {e}", exc_info=True)
        return {
            "status": "error",
            "message": str(e)
        }


@router.get("/pending-predictions")
async def get_pending_predictions(
    prediction_repo=Depends(get_prediction_repo)
):
    """Get list of pending predictions awaiting market results"""
    from ....core.response_cache import response_cache
    
    # Cache for 30 seconds (pending predictions can change)
    cache_key = "pending_predictions"
    cached = response_cache.get(cache_key, ttl=30)
    if cached is not None:
        return cached
    
    try:
        pending = prediction_repo.get_pending_predictions()
        result = {
            "status": "success",
            "data": {
                "pending_count": len(pending),
                "predictions": pending
            }
        }
        # Cache the result
        response_cache.set(cache_key, result, ttl=30)
        return result
    except Exception as e:
        from ....core.logging_config import get_logger
        logger = get_logger(__name__)
        logger.error(f"Error getting pending predictions: {e}", exc_info=True)
        return {
            "status": "error",
            "message": str(e)
        }


@router.post("/update-pending-predictions")
async def update_pending_predictions(
    market_data_service=Depends(get_market_data_service)
):
    """Update pending predictions with actual market prices"""
    try:
        result = market_data_service.update_pending_predictions()
        return result
    except Exception as e:
        from ....core.logging_config import get_logger
        logger = get_logger(__name__)
        logger.error(f"Error updating pending predictions: {e}", exc_info=True)
        return {
            "status": "error",
            "message": str(e)
        }


@router.get("/prediction-history")
async def get_prediction_history(
    days: int = 30,
    prediction_repo=Depends(get_prediction_repo)
):
    """Get historical predictions"""
    from ....core.response_cache import response_cache
    
    # Cache based on days parameter (60 seconds TTL)
    cache_key = f"prediction_history_{days}"
    cached = response_cache.get(cache_key, ttl=60)
    if cached is not None:
        return cached
    
    try:
        predictions = prediction_repo.get_historical_predictions(days=days)
        # Format to match frontend expectations
        formatted_predictions = []
        for pred in predictions:
            formatted_predictions.append({
                "date": pred['date'],
                "predicted_price": pred['predicted_price'],
                "actual_price": pred['actual_price'],
                "accuracy_percentage": pred.get('accuracy_percentage'),
                "status": "completed" if pred['actual_price'] is not None else "pending",
                "method": pred.get('method', 'Lasso Regression')
            })
        result = {
            "status": "success",
            "predictions": formatted_predictions,
            "total": len(formatted_predictions)
        }
        # Cache the result
        response_cache.set(cache_key, result, ttl=60)
        return result
    except Exception as e:
        from ....core.logging_config import get_logger
        logger = get_logger(__name__)
        logger.error(f"Error getting prediction history: {e}", exc_info=True)
        return {
            "status": "error",
            "message": str(e)
        }


@router.get("/prediction-reasons")
async def get_prediction_reasons(
    market_data_service=Depends(get_market_data_service),
    prediction_service=Depends(get_prediction_service),
    prediction_repo=Depends(get_prediction_repo)
):
    """Get AI-generated reasons for the current prediction
    
    If reasons don't exist in database, generates them on-demand, saves to database, and returns them.
    Returns error status with message if generation fails.
    """
    from ....core.logging_config import get_logger
    logger = get_logger(__name__)
    
    try:
        # Get prediction details (including saved reasons)
        try:
            from ....services.market_data_service import get_next_trading_day
            next_trading_day_dt = get_next_trading_day()
            next_day = next_trading_day_dt.strftime("%Y-%m-%d")
            
            if not prediction_repo.prediction_exists_for_date(next_day):
                logger.warning(f"No prediction found for {next_day}")
                return {
                    "status": "error",
                    "message": f"No prediction found for {next_day}",
                    "reasons": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            stored_prediction = prediction_repo.get_prediction_details_for_date(next_day)
            
            if not stored_prediction:
                return {
                    "status": "error",
                    "message": "No prediction details available",
                    "reasons": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Get saved prediction reasons from database
            prediction_reasons = stored_prediction.get('prediction_reasons')
            
            if prediction_reasons:
                logger.debug(f"Returning saved prediction reasons for {next_day}")
                return {
                    "status": "success",
                    "reasons": prediction_reasons,
                    "timestamp": datetime.now().isoformat(),
                    "source": "database"
                }
            
            # No reasons saved - generate them on-demand
            logger.info(f"ü§ñ No saved reasons found for {next_day}. Generating on-demand...")
            
            # Check if AI service is available
            try:
                from ai.services.prediction_reason_service import PredictionReasonService
                from ai.services.gemini_service import GeminiService
                from ai.config import ai_config
                
                if not ai_config.is_configured():
                    logger.warning(f"Gemini API not configured. API key present: {ai_config.gemini_api_key is not None}")
                    return {
                        "status": "error",
                        "message": "AI service not configured. Please set GEMINI_API_KEY environment variable.",
                        "reasons": None,
                        "timestamp": datetime.now().isoformat()
                    }
                
                logger.debug(f"Gemini API configured. Model: {ai_config.gemini_model}, API Base: {ai_config.gemini_api_base}")
            except ImportError as e:
                logger.error(f"Failed to import AI services: {e}", exc_info=True)
                return {
                    "status": "error",
                    "message": "AI services not available.",
                    "reasons": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Get current price
            try:
                current_price_data = market_data_service.get_realtime_price()
                current_price = current_price_data.get('current_price', 0.0)
                status = current_price_data.get('status', 'success')
                
                if current_price <= 0:
                    # If rate limited, provide more informative message
                    if status == 'rate_limited':
                        rate_limit_info = current_price_data.get('rate_limit_info', {})
                        wait_seconds = rate_limit_info.get('wait_seconds', 0)
                        logger.warning(f"Invalid current price: {current_price} (rate limited, retry after {wait_seconds}s)")
                        return {
                            "status": "rate_limited",
                            "message": f"Data provider rate limit. Please retry after {wait_seconds} seconds.",
                            "reasons": None,
                            "timestamp": datetime.now().isoformat(),
                            "rate_limit_info": rate_limit_info
                        }
                    logger.warning(f"Invalid current price: {current_price}")
                    return {
                        "status": "error",
                        "message": "Unable to fetch current market price.",
                        "reasons": None,
                        "timestamp": datetime.now().isoformat()
                    }
            except Exception as e:
                logger.error(f"Error fetching current price: {e}", exc_info=True)
                return {
                    "status": "error",
                    "message": f"Error fetching current market price: {str(e)}",
                    "reasons": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Get predicted price and method
            predicted_price = stored_prediction.get('predicted_price')
            prediction_method = stored_prediction.get('method') or prediction_service.get_model_display_name()
            
            if predicted_price is None:
                return {
                    "status": "error",
                    "message": "No predicted price available",
                    "reasons": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Get last 10 days of predictions
            try:
                historical_predictions = prediction_repo.get_historical_predictions(days=10)
                formatted_predictions = []
                for pred in historical_predictions:
                    formatted_predictions.append({
                        "date": pred['date'],
                        "predicted_price": pred['predicted_price'],
                        "actual_price": pred.get('actual_price'),
                        "accuracy_percentage": pred.get('accuracy_percentage'),
                        "method": pred.get('method', 'Lasso Regression')
                    })
            except Exception as e:
                logger.warning(f"Error getting historical predictions: {e}")
                formatted_predictions = []
            
            # Get aggregated news sentiment (excluding Alpha Vantage data)
            news_info = None
            try:
                from models.news_prediction import NewsSentimentAnalyzer
                news_analyzer = NewsSentimentAnalyzer()
                # Get aggregated sentiment metrics and top headlines (last 7 days)
                news_info = news_analyzer.get_aggregated_sentiment_for_gemini(days_back=7)
                
                if news_info.get('news_volume', 0) > 0:
                    logger.debug(f"üì∞ Fetched news sentiment: {news_info.get('news_volume')} articles, sentiment: {news_info.get('combined_sentiment', 0):.2f}")
                else:
                    logger.debug("üì∞ No news data available for Gemini")
                    news_info = None
            except Exception as news_error:
                logger.warning(f"‚ö†Ô∏è Error fetching news for Gemini: {news_error}")
                news_info = None  # Continue without news
            
            # Generate reasons using AI
            try:
                logger.info(f"ü§ñ Starting prediction reason generation for {next_day}")
                logger.debug(f"Input data: current_price=${current_price:.2f}, predicted_price=${predicted_price:.2f}, method={prediction_method}")
                logger.debug(f"Historical predictions: {len(formatted_predictions)} entries")
                logger.debug(f"News info: {'available' if news_info and news_info.get('news_volume', 0) > 0 else 'not available'}")
                
                gemini_service = GeminiService()
                reason_service = PredictionReasonService(gemini_service)
                
                prediction_reasons = reason_service.generate_prediction_reasons(
                    current_price=current_price,
                    predicted_price=predicted_price,
                    prediction_date=next_day,
                    prediction_method=prediction_method,
                    historical_predictions=formatted_predictions,
                    news_info=news_info  # Aggregated sentiment metrics (excluding Alpha Vantage)
                )
                
                logger.debug(f"Generation result: {'success' if prediction_reasons else 'failed'}")
                
                if prediction_reasons:
                    # Save reasons to database
                    try:
                        prediction_repo.save_prediction(
                            next_day,
                            predicted_price,
                            actual_price=stored_prediction.get('actual_price'),
                            prediction_method=prediction_method,
                            prediction_reasons=prediction_reasons
                        )
                        logger.info(f"‚úÖ Generated and saved prediction reasons for {next_day}")
                    except Exception as save_error:
                        logger.warning(f"‚ö†Ô∏è Failed to save prediction reasons to database: {save_error}")
                        # Still return the reasons even if save failed
                    
                    return {
                        "status": "success",
                        "reasons": prediction_reasons,
                        "timestamp": datetime.now().isoformat(),
                        "source": "generated"
                    }
                else:
                    logger.warning(f"‚ö†Ô∏è Failed to generate prediction reasons for {next_day} - Gemini returned None")
                    return {
                        "status": "error",
                        "message": "Failed to generate prediction reasons. This may be due to API quota limits or configuration issues. Please check backend logs for details.",
                        "reasons": None,
                        "timestamp": datetime.now().isoformat()
                    }
            except Exception as gen_error:
                error_msg = str(gen_error)
                logger.error(f"Error generating prediction reasons: {error_msg}", exc_info=True)
                
                # Provide user-friendly error messages
                if "quota" in error_msg.lower() or "429" in error_msg:
                    user_message = "API quota limit reached. Please try again later or check your Gemini API plan."
                elif "not configured" in error_msg.lower() or "api key" in error_msg.lower():
                    user_message = "AI service not configured. Please set GEMINI_API_KEY in your environment."
                elif "timeout" in error_msg.lower():
                    user_message = "Request timed out. Please try again."
                else:
                    user_message = f"Error generating analysis: {error_msg[:100]}"
                
                return {
                    "status": "error",
                    "message": user_message,
                    "reasons": None,
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Error retrieving prediction reasons: {e}", exc_info=True)
            return {
                "status": "error",
                "message": f"Error retrieving prediction reasons: {str(e)}",
                "reasons": None,
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"Unexpected error getting prediction reasons: {e}", exc_info=True)
        return {
            "status": "error",
            "message": f"Unexpected error: {str(e)}",
            "reasons": None,
            "timestamp": datetime.now().isoformat()
        }


